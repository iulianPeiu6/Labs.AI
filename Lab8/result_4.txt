Computer architecture deals with the design of computers, data storage devices, and networking components that store and run programs, transmit data, and drive interactions between computers, across networks, and with users.
Computer architects use parallelism and various strategies for memory organization to design computing systems with very high performance.
Computer architecture requires strong communication between computer scientists and computer engineers, since they both focus fundamentally on hardware design.
At its most fundamental level, a computer consists of a control unit, an arithmetic logic unit (ALU), a memory unit, and input/output (I/O) controllers.
The control unit fetches data and instructions from memory and uses operations of the ALU to carry out those instructions using that data.
When an input or output instruction is encountered, the control unit transfers the data between the memory and the designated I/O controller.
The operational speed of the CPU primarily determines the speed of the computer as a whole.
Current research includes cache design and algorithms that can predict what data is likely to be needed next and preload it into the cache for improved performance.
I/O controllers connect the computer to specific input devices (such as keyboards and touch screen displays) for feeding information to the memory, and output devices (such as printers and displays) for transmitting information from the memory to users.
Additional I/O controllers connect the computer to a network via ports that provide the conduit through which data flows when the computer is connected to the Internet.
Disk drives are used for maintaining permanent data.
They can be either permanently or temporarily attached to the computer in the form of a compact disc (CD), a digital video disc (DVD), or a memory stick (also called a flash drive).
The operation of a computer, once a program and some data have been loaded into RAM, takes place as follows.
At this level, the operation of a computer is not much different from that of a pocket calculator.
Most importantly, computer languages include conditional instructions—essentially, rules that say, “If memory location n satisfies condition a, do instruction number x next, otherwise do instruction y.” This allows the course of a program to be determined by the results of previous operations—a critically important ability.
Computer architectures that can execute sequences of instructions, conditional instructions, and loops are called “Turing complete,” which means that they can carry out the execution of any algorithm that can be defined.
Turing completeness is a fundamental and essential characteristic of any computer organization.
Logic design is the area of computer science that deals with the design of electronic circuits using the fundamental principles and properties of logic (see Boolean algebra) to carry out the operations of the control unit, the ALU, the I/O controllers, and other hardware.
The design of the control unit provides the circuits that interpret instructions.
Due to the need for efficiency, logic design must also optimize the circuitry to function with maximum speed and has a minimum number of gates and circuits.
An important area related to architecture is the design of microprocessors, which are complete CPUs—control unit, ALU, and memory—on a single integrated circuit chip.
Additional memory and I/O control circuitry are linked to this chip to form a complete computer.
VLSI microprocessor design occurs in a number of stages, which include creating the initial functional or behavioral specification, encoding this specification into a hardware description language, and breaking down the design into modules and generating sizes and shapes for the eventual chip components.
It also involves chip planning, which includes building a “floor plan” to indicate where on the chip each component should be placed and connected to other components.
Computer scientists are also involved in creating the computer-aided design (CAD) tools that support engineers in the various stages of chip design and in developing the necessary theoretical results, such as how to efficiently design a floor plan with near-minimal area that satisfies the given constraints.
Gordon E. Moore observed that the number of transistors on a computer chip was doubling about every 18–24 months.
As shown in the logarithmic graph of the number of transistors on Intel's processors at the time of their introduction, his “law” was being obeyed.
Fault tolerance is the ability of a computer to continue operation when one or more of its components fails.
To ensure fault tolerance, key components are often replicated so that the backup component can take over if needed.
Computer scientists are involved in the analysis of such replicated systems, providing theoretical approaches to estimating the reliability achieved by a given configuration and processor parameters, such as average time between failures and average time required to repair the processor.
For example, an advantage of a distributed database is that data replicated on different network hosts can provide a natural backup mechanism when one host fails.
Computational science has evolved rapidly, especially because of the dramatic growth in the volume of data transmitted from scientific instruments.
This phenomenon has been called the “big data” problem.
The mathematical methods needed for computational science require the transformation of equations and functions from the continuous to the discrete.
For example, the computer integration of a function over an interval is accomplished not by applying integral calculus but rather by approximating the area under the function graph as a sum of the areas obtained from evaluating the function at discrete points.
Similarly, the solution of a differential equation is obtained as a sequence of discrete points determined by approximating the true solution curve by a sequence of tangential line segments.
Several factors must be considered when applying numerical methods: (1) the conditions under which the method yields a solution, (2) the accuracy of the solution, (3) whether the solution process is stable (i.e., does not exhibit error growth), and (4) the computational complexity (in the sense described above) of obtaining a solution of the desired accuracy.
The requirements of big-data scientific problems, including the solution of ever larger systems of equations, engage the use of large and powerful arrays of processors (called multiprocessors or supercomputers) that allow many calculations to proceed in parallel by assigning them to separate processing elements.
These activities have sparked much interest in parallel computer architecture and algorithms that can be carried out efficiently on such machines.
Graphics and visual computing is the field that deals with the display and control of images on a computer screen.
Applications of graphics include CAD, fine arts, medical imaging, scientific data visualization, and video games.
CAD systems allow the computer to be used for designing objects ranging from automobile parts to bridges to computer chips by providing an interactive drawing tool and an engineering interface to simulation and analysis tools.
Fine arts applications allow artists to use the computer screen as a medium to create images, cinematographic special effects, animated cartoons, and television commercials.
Medical imaging applications involve the visualization of data obtained from technologies such as X-rays and magnetic resonance imaging (MRIs) to assist doctors in diagnosing medical conditions.
Scientific visualization uses massive amounts of data to define simulations of scientific phenomena, such as ocean modeling, to produce pictures that provide more insight into the phenomena than would tables of numbers.
A challenge for computer graphics is the development of efficient algorithms that manipulate the myriad of lines, triangles, and polygons that make up a computer image.
(For more technical details of graphics displays, see computer graphics.)
User interface design impacts the life cycle of software, so it should occur early in the design process.
In the 1960s, user interfaces consisted of computer consoles that allowed an operator directly to type commands that could be executed immediately or at some future time.
Thus, the field of HCI emerged to model, develop, and measure the effectiveness of various types of interfaces between a computer application and the person accessing its services.
GUIs enable users to communicate with the computer by such simple means as pointing to an icon with a mouse or touching it with a stylus or forefinger.
This technology also supports windowing environments on a computer screen, which allow users to work with different applications simultaneously, one in each window.
